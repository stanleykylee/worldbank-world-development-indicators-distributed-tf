{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A Dynamic Recurrent Neural Network (LSTM) implementation example using\n",
    "TensorFlow library. This example is using a toy dataset to classify linear\n",
    "sequences. The generated sequences have variable length.\n",
    "\n",
    "Long Short Term Memory paper: http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "# ====================\n",
    "#  TOY DATA GENERATOR\n",
    "# ====================\n",
    "class ToySequenceData(object):\n",
    "    \"\"\" Generate sequence of data with dynamic length.\n",
    "    This class generate samples for training:\n",
    "    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n",
    "    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n",
    "\n",
    "    NOTICE:\n",
    "    We have to pad each sequence to reach 'max_seq_len' for TensorFlow\n",
    "    consistency (we cannot feed a numpy array with inconsistent\n",
    "    dimensions). The dynamic calculation will then be perform thanks to\n",
    "    'seqlen' attribute that records every actual sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, source_data, dataset):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.seqlen = []\n",
    "        src_data = []\n",
    "        if dataset == \"train\":\n",
    "            src_data = source_data[:int((len(source_data)+1)*.80)]\n",
    "        elif dataset == \"test\":\n",
    "            src_data = source_data[int(len(source_data)*.80+1):]\n",
    "        i = 0\n",
    "        for row in src_data:\n",
    "            self.seqlen.append(24)\n",
    "            label = row.pop(-1)\n",
    "            self.data.append(row)\n",
    "            if label[0] < 5:\n",
    "                self.labels.append([1., 0.])\n",
    "            else:\n",
    "                self.labels.append([0., 1.])\n",
    "            i += 1\n",
    "        self.batch_id = 0\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "        \"\"\"\n",
    "        if self.batch_id == len(self.data):\n",
    "            self.batch_id = 0\n",
    "        batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "        return batch_data, batch_labels, batch_seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ==========\n",
    "#   MODEL\n",
    "# ==========\n",
    "# Data sets\n",
    "file=open(\"time-series.csv\",\"r\")\n",
    "data=list()\n",
    "for line in file:\n",
    "    data.append([[float(x)] for x in line.split(',')])\n",
    "file.close()\n",
    "random.shuffle(data)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_iters = 1000000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 24 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "trainset = ToySequenceData(source_data=data, dataset=\"train\")\n",
    "testset = ToySequenceData(source_data=data, dataset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, seq_max_len, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.stack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1280, Minibatch Loss= 0.649980, Training Accuracy= 0.56250\n",
      "Iter 2560, Minibatch Loss= 0.683144, Training Accuracy= 0.55469\n",
      "Iter 3840, Minibatch Loss= 0.629245, Training Accuracy= 0.57812\n",
      "Iter 5120, Minibatch Loss= 0.565284, Training Accuracy= 0.74219\n",
      "Iter 6400, Minibatch Loss= 0.623614, Training Accuracy= 0.59375\n",
      "Iter 7680, Minibatch Loss= 0.421968, Training Accuracy= 0.85938\n",
      "Iter 8960, Minibatch Loss= 0.412519, Training Accuracy= 0.82812\n",
      "Iter 10240, Minibatch Loss= 0.454805, Training Accuracy= 0.82031\n",
      "Iter 11520, Minibatch Loss= 0.350485, Training Accuracy= 0.89062\n",
      "Iter 12800, Minibatch Loss= 0.305719, Training Accuracy= 0.88281\n",
      "Iter 14080, Minibatch Loss= 0.304643, Training Accuracy= 0.91406\n",
      "Iter 15360, Minibatch Loss= 0.254780, Training Accuracy= 0.93750\n",
      "Iter 16640, Minibatch Loss= 0.307033, Training Accuracy= 0.89062\n",
      "Iter 17920, Minibatch Loss= 0.315927, Training Accuracy= 0.90625\n",
      "Iter 19200, Minibatch Loss= 0.301178, Training Accuracy= 0.89844\n",
      "Iter 20480, Minibatch Loss= 0.311618, Training Accuracy= 0.87500\n",
      "Iter 21760, Minibatch Loss= 0.292002, Training Accuracy= 0.89062\n",
      "Iter 23040, Minibatch Loss= 0.359321, Training Accuracy= 0.83594\n",
      "Iter 24320, Minibatch Loss= 0.293503, Training Accuracy= 0.89062\n",
      "Iter 25600, Minibatch Loss= 0.256852, Training Accuracy= 0.90625\n",
      "Iter 26880, Minibatch Loss= 0.297213, Training Accuracy= 0.85156\n",
      "Iter 28160, Minibatch Loss= 0.209528, Training Accuracy= 0.92969\n",
      "Iter 29440, Minibatch Loss= 0.281352, Training Accuracy= 0.88281\n",
      "Iter 30720, Minibatch Loss= 0.329431, Training Accuracy= 0.86719\n",
      "Iter 32000, Minibatch Loss= 0.305905, Training Accuracy= 0.87500\n",
      "Iter 33280, Minibatch Loss= 0.317097, Training Accuracy= 0.86719\n",
      "Iter 34560, Minibatch Loss= 0.255331, Training Accuracy= 0.89062\n",
      "Iter 35840, Minibatch Loss= 0.236365, Training Accuracy= 0.91406\n",
      "Iter 37120, Minibatch Loss= 0.218626, Training Accuracy= 0.92969\n",
      "Iter 38400, Minibatch Loss= 0.219074, Training Accuracy= 0.92188\n",
      "Iter 39680, Minibatch Loss= 0.246072, Training Accuracy= 0.92188\n",
      "Iter 40960, Minibatch Loss= 0.214410, Training Accuracy= 0.92188\n",
      "Iter 42240, Minibatch Loss= 0.285969, Training Accuracy= 0.88281\n",
      "Iter 43520, Minibatch Loss= 0.323542, Training Accuracy= 0.85156\n",
      "Iter 44800, Minibatch Loss= 0.219972, Training Accuracy= 0.92188\n",
      "Iter 46080, Minibatch Loss= 0.267425, Training Accuracy= 0.89844\n",
      "Iter 47360, Minibatch Loss= 0.180969, Training Accuracy= 0.94531\n",
      "Iter 48640, Minibatch Loss= 0.253607, Training Accuracy= 0.89062\n",
      "Iter 49920, Minibatch Loss= 0.160939, Training Accuracy= 0.94340\n",
      "Iter 51200, Minibatch Loss= 0.272165, Training Accuracy= 0.89062\n",
      "Iter 52480, Minibatch Loss= 0.209429, Training Accuracy= 0.91406\n",
      "Iter 53760, Minibatch Loss= 0.319235, Training Accuracy= 0.88281\n",
      "Iter 55040, Minibatch Loss= 0.241746, Training Accuracy= 0.90625\n",
      "Iter 56320, Minibatch Loss= 0.261046, Training Accuracy= 0.89062\n",
      "Iter 57600, Minibatch Loss= 0.245100, Training Accuracy= 0.89062\n",
      "Iter 58880, Minibatch Loss= 0.336792, Training Accuracy= 0.85938\n",
      "Iter 60160, Minibatch Loss= 0.288321, Training Accuracy= 0.85156\n",
      "Iter 61440, Minibatch Loss= 0.252098, Training Accuracy= 0.92188\n",
      "Iter 62720, Minibatch Loss= 0.242064, Training Accuracy= 0.90625\n",
      "Iter 64000, Minibatch Loss= 0.236847, Training Accuracy= 0.92969\n",
      "Iter 65280, Minibatch Loss= 0.197976, Training Accuracy= 0.93750\n",
      "Iter 66560, Minibatch Loss= 0.247626, Training Accuracy= 0.90625\n",
      "Iter 67840, Minibatch Loss= 0.275975, Training Accuracy= 0.90625\n",
      "Iter 69120, Minibatch Loss= 0.257686, Training Accuracy= 0.91406\n",
      "Iter 70400, Minibatch Loss= 0.257394, Training Accuracy= 0.88281\n",
      "Iter 71680, Minibatch Loss= 0.264982, Training Accuracy= 0.89062\n",
      "Iter 72960, Minibatch Loss= 0.339579, Training Accuracy= 0.84375\n",
      "Iter 74240, Minibatch Loss= 0.263490, Training Accuracy= 0.89062\n",
      "Iter 75520, Minibatch Loss= 0.227142, Training Accuracy= 0.92969\n",
      "Iter 76800, Minibatch Loss= 0.288348, Training Accuracy= 0.87500\n",
      "Iter 78080, Minibatch Loss= 0.185202, Training Accuracy= 0.92969\n",
      "Iter 79360, Minibatch Loss= 0.263783, Training Accuracy= 0.88281\n",
      "Iter 80640, Minibatch Loss= 0.311680, Training Accuracy= 0.88281\n",
      "Iter 81920, Minibatch Loss= 0.302634, Training Accuracy= 0.87500\n",
      "Iter 83200, Minibatch Loss= 0.305426, Training Accuracy= 0.86719\n",
      "Iter 84480, Minibatch Loss= 0.231360, Training Accuracy= 0.90625\n",
      "Iter 85760, Minibatch Loss= 0.218997, Training Accuracy= 0.91406\n",
      "Iter 87040, Minibatch Loss= 0.204549, Training Accuracy= 0.92969\n",
      "Iter 88320, Minibatch Loss= 0.203050, Training Accuracy= 0.91406\n",
      "Iter 89600, Minibatch Loss= 0.234130, Training Accuracy= 0.91406\n",
      "Iter 90880, Minibatch Loss= 0.190825, Training Accuracy= 0.92969\n",
      "Iter 92160, Minibatch Loss= 0.272708, Training Accuracy= 0.89062\n",
      "Iter 93440, Minibatch Loss= 0.311469, Training Accuracy= 0.84375\n",
      "Iter 94720, Minibatch Loss= 0.205161, Training Accuracy= 0.92188\n",
      "Iter 96000, Minibatch Loss= 0.245467, Training Accuracy= 0.91406\n",
      "Iter 97280, Minibatch Loss= 0.162434, Training Accuracy= 0.94531\n",
      "Iter 98560, Minibatch Loss= 0.242883, Training Accuracy= 0.88281\n",
      "Iter 99840, Minibatch Loss= 0.150473, Training Accuracy= 0.94340\n",
      "Iter 101120, Minibatch Loss= 0.260212, Training Accuracy= 0.89062\n",
      "Iter 102400, Minibatch Loss= 0.196117, Training Accuracy= 0.91406\n",
      "Iter 103680, Minibatch Loss= 0.330171, Training Accuracy= 0.86719\n",
      "Iter 104960, Minibatch Loss= 0.233978, Training Accuracy= 0.93750\n",
      "Iter 106240, Minibatch Loss= 0.248863, Training Accuracy= 0.90625\n",
      "Iter 107520, Minibatch Loss= 0.235810, Training Accuracy= 0.89844\n",
      "Iter 108800, Minibatch Loss= 0.330258, Training Accuracy= 0.86719\n",
      "Iter 110080, Minibatch Loss= 0.283796, Training Accuracy= 0.85156\n",
      "Iter 111360, Minibatch Loss= 0.239516, Training Accuracy= 0.91406\n",
      "Iter 112640, Minibatch Loss= 0.222405, Training Accuracy= 0.91406\n",
      "Iter 113920, Minibatch Loss= 0.218998, Training Accuracy= 0.92188\n",
      "Iter 115200, Minibatch Loss= 0.193193, Training Accuracy= 0.93750\n",
      "Iter 116480, Minibatch Loss= 0.233640, Training Accuracy= 0.91406\n",
      "Iter 117760, Minibatch Loss= 0.264904, Training Accuracy= 0.90625\n",
      "Iter 119040, Minibatch Loss= 0.246959, Training Accuracy= 0.92188\n",
      "Iter 120320, Minibatch Loss= 0.239856, Training Accuracy= 0.90625\n",
      "Iter 121600, Minibatch Loss= 0.249287, Training Accuracy= 0.89062\n",
      "Iter 122880, Minibatch Loss= 0.325922, Training Accuracy= 0.85156\n",
      "Iter 124160, Minibatch Loss= 0.251479, Training Accuracy= 0.89062\n",
      "Iter 125440, Minibatch Loss= 0.212230, Training Accuracy= 0.92969\n",
      "Iter 126720, Minibatch Loss= 0.278934, Training Accuracy= 0.88281\n",
      "Iter 128000, Minibatch Loss= 0.173716, Training Accuracy= 0.93750\n",
      "Iter 129280, Minibatch Loss= 0.247615, Training Accuracy= 0.89062\n",
      "Iter 130560, Minibatch Loss= 0.295403, Training Accuracy= 0.87500\n",
      "Iter 131840, Minibatch Loss= 0.294568, Training Accuracy= 0.86719\n",
      "Iter 133120, Minibatch Loss= 0.293545, Training Accuracy= 0.87500\n",
      "Iter 134400, Minibatch Loss= 0.215402, Training Accuracy= 0.91406\n",
      "Iter 135680, Minibatch Loss= 0.206915, Training Accuracy= 0.92188\n",
      "Iter 136960, Minibatch Loss= 0.197230, Training Accuracy= 0.92969\n",
      "Iter 138240, Minibatch Loss= 0.195094, Training Accuracy= 0.91406\n",
      "Iter 139520, Minibatch Loss= 0.223995, Training Accuracy= 0.91406\n",
      "Iter 140800, Minibatch Loss= 0.177609, Training Accuracy= 0.92969\n",
      "Iter 142080, Minibatch Loss= 0.264963, Training Accuracy= 0.89062\n",
      "Iter 143360, Minibatch Loss= 0.297808, Training Accuracy= 0.85156\n",
      "Iter 144640, Minibatch Loss= 0.195449, Training Accuracy= 0.92188\n",
      "Iter 145920, Minibatch Loss= 0.230401, Training Accuracy= 0.92188\n",
      "Iter 147200, Minibatch Loss= 0.149813, Training Accuracy= 0.96094\n",
      "Iter 148480, Minibatch Loss= 0.230193, Training Accuracy= 0.89062\n",
      "Iter 149760, Minibatch Loss= 0.142613, Training Accuracy= 0.94340\n",
      "Iter 151040, Minibatch Loss= 0.248984, Training Accuracy= 0.89844\n",
      "Iter 152320, Minibatch Loss= 0.185969, Training Accuracy= 0.92188\n",
      "Iter 153600, Minibatch Loss= 0.296610, Training Accuracy= 0.89844\n",
      "Iter 154880, Minibatch Loss= 0.221459, Training Accuracy= 0.92188\n",
      "Iter 156160, Minibatch Loss= 0.238562, Training Accuracy= 0.91406\n",
      "Iter 157440, Minibatch Loss= 0.220599, Training Accuracy= 0.91406\n",
      "Iter 158720, Minibatch Loss= 0.322104, Training Accuracy= 0.87500\n",
      "Iter 160000, Minibatch Loss= 0.270939, Training Accuracy= 0.87500\n",
      "Iter 161280, Minibatch Loss= 0.224084, Training Accuracy= 0.91406\n",
      "Iter 162560, Minibatch Loss= 0.208280, Training Accuracy= 0.93750\n",
      "Iter 163840, Minibatch Loss= 0.207151, Training Accuracy= 0.92969\n",
      "Iter 165120, Minibatch Loss= 0.187042, Training Accuracy= 0.94531\n",
      "Iter 166400, Minibatch Loss= 0.220160, Training Accuracy= 0.91406\n",
      "Iter 167680, Minibatch Loss= 0.250454, Training Accuracy= 0.90625\n",
      "Iter 168960, Minibatch Loss= 0.236566, Training Accuracy= 0.92188\n",
      "Iter 170240, Minibatch Loss= 0.237313, Training Accuracy= 0.90625\n",
      "Iter 171520, Minibatch Loss= 0.233323, Training Accuracy= 0.91406\n",
      "Iter 172800, Minibatch Loss= 0.315371, Training Accuracy= 0.85156\n",
      "Iter 174080, Minibatch Loss= 0.241907, Training Accuracy= 0.90625\n",
      "Iter 175360, Minibatch Loss= 0.200854, Training Accuracy= 0.93750\n",
      "Iter 176640, Minibatch Loss= 0.264607, Training Accuracy= 0.89062\n",
      "Iter 177920, Minibatch Loss= 0.164218, Training Accuracy= 0.92188\n",
      "Iter 179200, Minibatch Loss= 0.231316, Training Accuracy= 0.89844\n",
      "Iter 180480, Minibatch Loss= 0.279976, Training Accuracy= 0.88281\n",
      "Iter 181760, Minibatch Loss= 0.280871, Training Accuracy= 0.88281\n",
      "Iter 183040, Minibatch Loss= 0.276267, Training Accuracy= 0.87500\n",
      "Iter 184320, Minibatch Loss= 0.197328, Training Accuracy= 0.92188\n",
      "Iter 185600, Minibatch Loss= 0.192175, Training Accuracy= 0.92188\n",
      "Iter 186880, Minibatch Loss= 0.187916, Training Accuracy= 0.92969\n",
      "Iter 188160, Minibatch Loss= 0.185510, Training Accuracy= 0.92969\n",
      "Iter 189440, Minibatch Loss= 0.209724, Training Accuracy= 0.91406\n",
      "Iter 190720, Minibatch Loss= 0.162683, Training Accuracy= 0.95312\n",
      "Iter 192000, Minibatch Loss= 0.248122, Training Accuracy= 0.90625\n",
      "Iter 193280, Minibatch Loss= 0.278702, Training Accuracy= 0.85938\n",
      "Iter 194560, Minibatch Loss= 0.187299, Training Accuracy= 0.92969\n",
      "Iter 195840, Minibatch Loss= 0.216974, Training Accuracy= 0.92188\n",
      "Iter 197120, Minibatch Loss= 0.155925, Training Accuracy= 0.95312\n",
      "Iter 198400, Minibatch Loss= 0.209684, Training Accuracy= 0.89844\n",
      "Iter 199680, Minibatch Loss= 0.131704, Training Accuracy= 0.96226\n",
      "Iter 200960, Minibatch Loss= 0.230883, Training Accuracy= 0.89844\n",
      "Iter 202240, Minibatch Loss= 0.178049, Training Accuracy= 0.93750\n",
      "Iter 203520, Minibatch Loss= 0.282440, Training Accuracy= 0.89844\n",
      "Iter 204800, Minibatch Loss= 0.209347, Training Accuracy= 0.92188\n",
      "Iter 206080, Minibatch Loss= 0.221815, Training Accuracy= 0.92969\n",
      "Iter 207360, Minibatch Loss= 0.199522, Training Accuracy= 0.90625\n",
      "Iter 208640, Minibatch Loss= 0.302894, Training Accuracy= 0.89062\n",
      "Iter 209920, Minibatch Loss= 0.249691, Training Accuracy= 0.87500\n",
      "Iter 211200, Minibatch Loss= 0.204088, Training Accuracy= 0.92188\n",
      "Iter 212480, Minibatch Loss= 0.196097, Training Accuracy= 0.93750\n",
      "Iter 213760, Minibatch Loss= 0.193817, Training Accuracy= 0.92188\n",
      "Iter 215040, Minibatch Loss= 0.177631, Training Accuracy= 0.94531\n",
      "Iter 216320, Minibatch Loss= 0.202088, Training Accuracy= 0.94531\n",
      "Iter 217600, Minibatch Loss= 0.229913, Training Accuracy= 0.92188\n",
      "Iter 218880, Minibatch Loss= 0.219915, Training Accuracy= 0.92188\n",
      "Iter 220160, Minibatch Loss= 0.241665, Training Accuracy= 0.89844\n",
      "Iter 221440, Minibatch Loss= 0.216913, Training Accuracy= 0.92969\n",
      "Iter 222720, Minibatch Loss= 0.346413, Training Accuracy= 0.85938\n",
      "Iter 224000, Minibatch Loss= 0.224571, Training Accuracy= 0.91406\n",
      "Iter 225280, Minibatch Loss= 0.195093, Training Accuracy= 0.92969\n",
      "Iter 226560, Minibatch Loss= 0.268911, Training Accuracy= 0.90625\n",
      "Iter 227840, Minibatch Loss= 0.149771, Training Accuracy= 0.92188\n",
      "Iter 229120, Minibatch Loss= 0.214476, Training Accuracy= 0.92188\n",
      "Iter 230400, Minibatch Loss= 0.253736, Training Accuracy= 0.89062\n",
      "Iter 231680, Minibatch Loss= 0.257616, Training Accuracy= 0.89062\n",
      "Iter 232960, Minibatch Loss= 0.252638, Training Accuracy= 0.88281\n",
      "Iter 234240, Minibatch Loss= 0.172003, Training Accuracy= 0.92969\n",
      "Iter 235520, Minibatch Loss= 0.169572, Training Accuracy= 0.93750\n",
      "Iter 236800, Minibatch Loss= 0.180933, Training Accuracy= 0.92188\n",
      "Iter 238080, Minibatch Loss= 0.173081, Training Accuracy= 0.92969\n",
      "Iter 239360, Minibatch Loss= 0.191930, Training Accuracy= 0.92969\n",
      "Iter 240640, Minibatch Loss= 0.140218, Training Accuracy= 0.97656\n",
      "Iter 241920, Minibatch Loss= 0.232855, Training Accuracy= 0.90625\n",
      "Iter 243200, Minibatch Loss= 0.256731, Training Accuracy= 0.85938\n",
      "Iter 244480, Minibatch Loss= 0.175575, Training Accuracy= 0.92969\n",
      "Iter 245760, Minibatch Loss= 0.198350, Training Accuracy= 0.93750\n",
      "Iter 247040, Minibatch Loss= 0.141729, Training Accuracy= 0.95312\n",
      "Iter 248320, Minibatch Loss= 0.181431, Training Accuracy= 0.90625\n",
      "Iter 249600, Minibatch Loss= 0.117946, Training Accuracy= 0.97170\n",
      "Iter 250880, Minibatch Loss= 0.208852, Training Accuracy= 0.91406\n",
      "Iter 252160, Minibatch Loss= 0.223100, Training Accuracy= 0.92188\n",
      "Iter 253440, Minibatch Loss= 0.263141, Training Accuracy= 0.91406\n",
      "Iter 254720, Minibatch Loss= 0.193356, Training Accuracy= 0.92188\n",
      "Iter 256000, Minibatch Loss= 0.204461, Training Accuracy= 0.92969\n",
      "Iter 257280, Minibatch Loss= 0.188822, Training Accuracy= 0.91406\n",
      "Iter 258560, Minibatch Loss= 0.279011, Training Accuracy= 0.89062\n",
      "Iter 259840, Minibatch Loss= 0.222702, Training Accuracy= 0.89844\n",
      "Iter 261120, Minibatch Loss= 0.182785, Training Accuracy= 0.92969\n",
      "Iter 262400, Minibatch Loss= 0.277493, Training Accuracy= 0.88281\n",
      "Iter 263680, Minibatch Loss= 0.177899, Training Accuracy= 0.92969\n",
      "Iter 264960, Minibatch Loss= 0.171525, Training Accuracy= 0.93750\n",
      "Iter 266240, Minibatch Loss= 0.185805, Training Accuracy= 0.94531\n",
      "Iter 267520, Minibatch Loss= 0.203045, Training Accuracy= 0.92188\n",
      "Iter 268800, Minibatch Loss= 0.198543, Training Accuracy= 0.93750\n",
      "Iter 270080, Minibatch Loss= 0.232506, Training Accuracy= 0.90625\n",
      "Iter 271360, Minibatch Loss= 0.198152, Training Accuracy= 0.92969\n",
      "Iter 272640, Minibatch Loss= 0.281012, Training Accuracy= 0.88281\n",
      "Iter 273920, Minibatch Loss= 0.212652, Training Accuracy= 0.90625\n",
      "Iter 275200, Minibatch Loss= 0.185779, Training Accuracy= 0.93750\n",
      "Iter 276480, Minibatch Loss= 0.289885, Training Accuracy= 0.88281\n",
      "Iter 277760, Minibatch Loss= 0.136411, Training Accuracy= 0.92969\n",
      "Iter 279040, Minibatch Loss= 0.177269, Training Accuracy= 0.94531\n",
      "Iter 280320, Minibatch Loss= 0.223500, Training Accuracy= 0.89844\n",
      "Iter 281600, Minibatch Loss= 0.236722, Training Accuracy= 0.89062\n",
      "Iter 282880, Minibatch Loss= 0.233309, Training Accuracy= 0.89844\n",
      "Iter 284160, Minibatch Loss= 0.147277, Training Accuracy= 0.96875\n",
      "Iter 285440, Minibatch Loss= 0.148812, Training Accuracy= 0.95312\n",
      "Iter 286720, Minibatch Loss= 0.179389, Training Accuracy= 0.92969\n",
      "Iter 288000, Minibatch Loss= 0.166058, Training Accuracy= 0.93750\n",
      "Iter 289280, Minibatch Loss= 0.179446, Training Accuracy= 0.93750\n",
      "Iter 290560, Minibatch Loss= 0.124496, Training Accuracy= 0.96875\n",
      "Iter 291840, Minibatch Loss= 0.200312, Training Accuracy= 0.92188\n",
      "Iter 293120, Minibatch Loss= 0.237770, Training Accuracy= 0.89844\n",
      "Iter 294400, Minibatch Loss= 0.173325, Training Accuracy= 0.93750\n",
      "Iter 295680, Minibatch Loss= 0.187652, Training Accuracy= 0.94531\n",
      "Iter 296960, Minibatch Loss= 0.149033, Training Accuracy= 0.93750\n",
      "Iter 298240, Minibatch Loss= 0.162509, Training Accuracy= 0.91406\n",
      "Iter 299520, Minibatch Loss= 0.107576, Training Accuracy= 0.97170\n",
      "Iter 300800, Minibatch Loss= 0.188182, Training Accuracy= 0.91406\n",
      "Iter 302080, Minibatch Loss= 0.203705, Training Accuracy= 0.92188\n",
      "Iter 303360, Minibatch Loss= 0.256856, Training Accuracy= 0.89062\n",
      "Iter 304640, Minibatch Loss= 0.173825, Training Accuracy= 0.93750\n",
      "Iter 305920, Minibatch Loss= 0.182664, Training Accuracy= 0.92969\n",
      "Iter 307200, Minibatch Loss= 0.176621, Training Accuracy= 0.92969\n",
      "Iter 308480, Minibatch Loss= 0.262521, Training Accuracy= 0.89844\n",
      "Iter 309760, Minibatch Loss= 0.198124, Training Accuracy= 0.91406\n",
      "Iter 311040, Minibatch Loss= 0.150221, Training Accuracy= 0.95312\n",
      "Iter 312320, Minibatch Loss= 0.251250, Training Accuracy= 0.91406\n",
      "Iter 313600, Minibatch Loss= 0.160046, Training Accuracy= 0.93750\n",
      "Iter 314880, Minibatch Loss= 0.153758, Training Accuracy= 0.93750\n",
      "Iter 316160, Minibatch Loss= 0.164080, Training Accuracy= 0.94531\n",
      "Iter 317440, Minibatch Loss= 0.215128, Training Accuracy= 0.92188\n",
      "Iter 318720, Minibatch Loss= 0.185545, Training Accuracy= 0.95312\n",
      "Iter 320000, Minibatch Loss= 0.187227, Training Accuracy= 0.92969\n",
      "Iter 321280, Minibatch Loss= 0.207930, Training Accuracy= 0.91406\n",
      "Iter 322560, Minibatch Loss= 0.321457, Training Accuracy= 0.87500\n",
      "Iter 323840, Minibatch Loss= 0.186968, Training Accuracy= 0.92969\n",
      "Iter 325120, Minibatch Loss= 0.184172, Training Accuracy= 0.92969\n",
      "Iter 326400, Minibatch Loss= 0.365103, Training Accuracy= 0.86719\n",
      "Iter 327680, Minibatch Loss= 0.126081, Training Accuracy= 0.96094\n",
      "Iter 328960, Minibatch Loss= 0.175650, Training Accuracy= 0.92969\n",
      "Iter 330240, Minibatch Loss= 0.202330, Training Accuracy= 0.92188\n",
      "Iter 331520, Minibatch Loss= 0.219517, Training Accuracy= 0.88281\n",
      "Iter 332800, Minibatch Loss= 0.217955, Training Accuracy= 0.90625\n",
      "Iter 334080, Minibatch Loss= 0.122138, Training Accuracy= 0.96875\n",
      "Iter 335360, Minibatch Loss= 0.137333, Training Accuracy= 0.95312\n",
      "Iter 336640, Minibatch Loss= 0.168938, Training Accuracy= 0.93750\n",
      "Iter 337920, Minibatch Loss= 0.161588, Training Accuracy= 0.93750\n",
      "Iter 339200, Minibatch Loss= 0.174974, Training Accuracy= 0.93750\n",
      "Iter 340480, Minibatch Loss= 0.118613, Training Accuracy= 0.96875\n",
      "Iter 341760, Minibatch Loss= 0.186395, Training Accuracy= 0.91406\n",
      "Iter 343040, Minibatch Loss= 0.219712, Training Accuracy= 0.89844\n",
      "Iter 344320, Minibatch Loss= 0.161320, Training Accuracy= 0.94531\n",
      "Iter 345600, Minibatch Loss= 0.191020, Training Accuracy= 0.93750\n",
      "Iter 346880, Minibatch Loss= 0.128268, Training Accuracy= 0.96875\n",
      "Iter 348160, Minibatch Loss= 0.149953, Training Accuracy= 0.94531\n",
      "Iter 349440, Minibatch Loss= 0.102898, Training Accuracy= 0.97170\n",
      "Iter 350720, Minibatch Loss= 0.168684, Training Accuracy= 0.92969\n",
      "Iter 352000, Minibatch Loss= 0.195779, Training Accuracy= 0.92188\n",
      "Iter 353280, Minibatch Loss= 0.236930, Training Accuracy= 0.91406\n",
      "Iter 354560, Minibatch Loss= 0.170189, Training Accuracy= 0.93750\n",
      "Iter 355840, Minibatch Loss= 0.188583, Training Accuracy= 0.92188\n",
      "Iter 357120, Minibatch Loss= 0.164250, Training Accuracy= 0.93750\n",
      "Iter 358400, Minibatch Loss= 0.243694, Training Accuracy= 0.91406\n",
      "Iter 359680, Minibatch Loss= 0.192682, Training Accuracy= 0.91406\n",
      "Iter 360960, Minibatch Loss= 0.145062, Training Accuracy= 0.94531\n",
      "Iter 362240, Minibatch Loss= 0.197239, Training Accuracy= 0.93750\n",
      "Iter 363520, Minibatch Loss= 0.145958, Training Accuracy= 0.94531\n",
      "Iter 364800, Minibatch Loss= 0.153618, Training Accuracy= 0.94531\n",
      "Iter 366080, Minibatch Loss= 0.173613, Training Accuracy= 0.94531\n",
      "Iter 367360, Minibatch Loss= 0.178708, Training Accuracy= 0.93750\n",
      "Iter 368640, Minibatch Loss= 0.178338, Training Accuracy= 0.94531\n",
      "Iter 369920, Minibatch Loss= 0.191614, Training Accuracy= 0.92188\n",
      "Iter 371200, Minibatch Loss= 0.211543, Training Accuracy= 0.91406\n",
      "Iter 372480, Minibatch Loss= 0.267737, Training Accuracy= 0.89062\n",
      "Iter 373760, Minibatch Loss= 0.185121, Training Accuracy= 0.92969\n",
      "Iter 375040, Minibatch Loss= 0.156023, Training Accuracy= 0.95312\n",
      "Iter 376320, Minibatch Loss= 0.423438, Training Accuracy= 0.85938\n",
      "Iter 377600, Minibatch Loss= 0.121387, Training Accuracy= 0.96094\n",
      "Iter 378880, Minibatch Loss= 0.159071, Training Accuracy= 0.93750\n",
      "Iter 380160, Minibatch Loss= 0.196484, Training Accuracy= 0.92969\n",
      "Iter 381440, Minibatch Loss= 0.217173, Training Accuracy= 0.89844\n",
      "Iter 382720, Minibatch Loss= 0.202592, Training Accuracy= 0.92188\n",
      "Iter 384000, Minibatch Loss= 0.109489, Training Accuracy= 0.96875\n",
      "Iter 385280, Minibatch Loss= 0.131488, Training Accuracy= 0.96094\n",
      "Iter 386560, Minibatch Loss= 0.161640, Training Accuracy= 0.93750\n",
      "Iter 387840, Minibatch Loss= 0.154570, Training Accuracy= 0.93750\n",
      "Iter 389120, Minibatch Loss= 0.155704, Training Accuracy= 0.93750\n",
      "Iter 390400, Minibatch Loss= 0.110626, Training Accuracy= 0.97656\n",
      "Iter 391680, Minibatch Loss= 0.207275, Training Accuracy= 0.90625\n",
      "Iter 392960, Minibatch Loss= 0.216589, Training Accuracy= 0.89062\n",
      "Iter 394240, Minibatch Loss= 0.153534, Training Accuracy= 0.94531\n",
      "Iter 395520, Minibatch Loss= 0.184103, Training Accuracy= 0.93750\n",
      "Iter 396800, Minibatch Loss= 0.107016, Training Accuracy= 0.97656\n",
      "Iter 398080, Minibatch Loss= 0.126994, Training Accuracy= 0.95312\n",
      "Iter 399360, Minibatch Loss= 0.094047, Training Accuracy= 0.97170\n",
      "Iter 400640, Minibatch Loss= 0.156557, Training Accuracy= 0.92188\n",
      "Iter 401920, Minibatch Loss= 0.247360, Training Accuracy= 0.92188\n",
      "Iter 403200, Minibatch Loss= 0.216211, Training Accuracy= 0.91406\n",
      "Iter 404480, Minibatch Loss= 0.162890, Training Accuracy= 0.93750\n",
      "Iter 405760, Minibatch Loss= 0.189075, Training Accuracy= 0.91406\n",
      "Iter 407040, Minibatch Loss= 0.153923, Training Accuracy= 0.93750\n",
      "Iter 408320, Minibatch Loss= 0.231054, Training Accuracy= 0.92188\n",
      "Iter 409600, Minibatch Loss= 0.171150, Training Accuracy= 0.92969\n",
      "Iter 410880, Minibatch Loss= 0.131120, Training Accuracy= 0.94531\n",
      "Iter 412160, Minibatch Loss= 0.246471, Training Accuracy= 0.91406\n",
      "Iter 413440, Minibatch Loss= 0.131985, Training Accuracy= 0.95312\n",
      "Iter 414720, Minibatch Loss= 0.150044, Training Accuracy= 0.93750\n",
      "Iter 416000, Minibatch Loss= 0.173255, Training Accuracy= 0.93750\n",
      "Iter 417280, Minibatch Loss= 0.159362, Training Accuracy= 0.93750\n",
      "Iter 418560, Minibatch Loss= 0.165309, Training Accuracy= 0.94531\n",
      "Iter 419840, Minibatch Loss= 0.187605, Training Accuracy= 0.92188\n",
      "Iter 421120, Minibatch Loss= 0.239679, Training Accuracy= 0.92188\n",
      "Iter 422400, Minibatch Loss= 0.258249, Training Accuracy= 0.89062\n",
      "Iter 423680, Minibatch Loss= 0.177637, Training Accuracy= 0.93750\n",
      "Iter 424960, Minibatch Loss= 0.145102, Training Accuracy= 0.95312\n",
      "Iter 426240, Minibatch Loss= 0.291519, Training Accuracy= 0.88281\n",
      "Iter 427520, Minibatch Loss= 0.108733, Training Accuracy= 0.96094\n",
      "Iter 428800, Minibatch Loss= 0.154317, Training Accuracy= 0.94531\n",
      "Iter 430080, Minibatch Loss= 0.184550, Training Accuracy= 0.92969\n",
      "Iter 431360, Minibatch Loss= 0.207867, Training Accuracy= 0.89844\n",
      "Iter 432640, Minibatch Loss= 0.192045, Training Accuracy= 0.92188\n",
      "Iter 433920, Minibatch Loss= 0.100265, Training Accuracy= 0.96875\n",
      "Iter 435200, Minibatch Loss= 0.115048, Training Accuracy= 0.96875\n",
      "Iter 436480, Minibatch Loss= 0.157631, Training Accuracy= 0.92969\n",
      "Iter 437760, Minibatch Loss= 0.149591, Training Accuracy= 0.95312\n",
      "Iter 439040, Minibatch Loss= 0.145549, Training Accuracy= 0.93750\n",
      "Iter 440320, Minibatch Loss= 0.108316, Training Accuracy= 0.96094\n",
      "Iter 441600, Minibatch Loss= 0.166071, Training Accuracy= 0.93750\n",
      "Iter 442880, Minibatch Loss= 0.210046, Training Accuracy= 0.89844\n",
      "Iter 444160, Minibatch Loss= 0.149512, Training Accuracy= 0.94531\n",
      "Iter 445440, Minibatch Loss= 0.171986, Training Accuracy= 0.94531\n",
      "Iter 446720, Minibatch Loss= 0.106473, Training Accuracy= 0.97656\n",
      "Iter 448000, Minibatch Loss= 0.116211, Training Accuracy= 0.95312\n",
      "Iter 449280, Minibatch Loss= 0.090242, Training Accuracy= 0.97170\n",
      "Iter 450560, Minibatch Loss= 0.146117, Training Accuracy= 0.93750\n",
      "Iter 451840, Minibatch Loss= 0.142203, Training Accuracy= 0.93750\n",
      "Iter 453120, Minibatch Loss= 0.209086, Training Accuracy= 0.91406\n",
      "Iter 454400, Minibatch Loss= 0.158118, Training Accuracy= 0.93750\n",
      "Iter 455680, Minibatch Loss= 0.188435, Training Accuracy= 0.91406\n",
      "Iter 456960, Minibatch Loss= 0.146765, Training Accuracy= 0.94531\n",
      "Iter 458240, Minibatch Loss= 0.221804, Training Accuracy= 0.91406\n",
      "Iter 459520, Minibatch Loss= 0.162771, Training Accuracy= 0.92969\n",
      "Iter 460800, Minibatch Loss= 0.124270, Training Accuracy= 0.95312\n",
      "Iter 462080, Minibatch Loss= 0.294146, Training Accuracy= 0.89062\n",
      "Iter 463360, Minibatch Loss= 0.122914, Training Accuracy= 0.96094\n",
      "Iter 464640, Minibatch Loss= 0.146059, Training Accuracy= 0.93750\n",
      "Iter 465920, Minibatch Loss= 0.169823, Training Accuracy= 0.93750\n",
      "Iter 467200, Minibatch Loss= 0.150604, Training Accuracy= 0.93750\n",
      "Iter 468480, Minibatch Loss= 0.160200, Training Accuracy= 0.94531\n",
      "Iter 469760, Minibatch Loss= 0.181992, Training Accuracy= 0.92188\n",
      "Iter 471040, Minibatch Loss= 0.235985, Training Accuracy= 0.92188\n",
      "Iter 472320, Minibatch Loss= 0.255115, Training Accuracy= 0.89062\n",
      "Iter 473600, Minibatch Loss= 0.170244, Training Accuracy= 0.94531\n",
      "Iter 474880, Minibatch Loss= 0.135028, Training Accuracy= 0.95312\n",
      "Iter 476160, Minibatch Loss= 0.253406, Training Accuracy= 0.90625\n",
      "Iter 477440, Minibatch Loss= 0.102639, Training Accuracy= 0.96875\n",
      "Iter 478720, Minibatch Loss= 0.139961, Training Accuracy= 0.96875\n",
      "Iter 480000, Minibatch Loss= 0.178219, Training Accuracy= 0.92969\n",
      "Iter 481280, Minibatch Loss= 0.201860, Training Accuracy= 0.89844\n",
      "Iter 482560, Minibatch Loss= 0.183552, Training Accuracy= 0.92188\n",
      "Iter 483840, Minibatch Loss= 0.092423, Training Accuracy= 0.97656\n",
      "Iter 485120, Minibatch Loss= 0.108773, Training Accuracy= 0.97656\n",
      "Iter 486400, Minibatch Loss= 0.152399, Training Accuracy= 0.92969\n",
      "Iter 487680, Minibatch Loss= 0.143971, Training Accuracy= 0.95312\n",
      "Iter 488960, Minibatch Loss= 0.135465, Training Accuracy= 0.93750\n",
      "Iter 490240, Minibatch Loss= 0.101876, Training Accuracy= 0.98438\n",
      "Iter 491520, Minibatch Loss= 0.157410, Training Accuracy= 0.92969\n",
      "Iter 492800, Minibatch Loss= 0.202571, Training Accuracy= 0.90625\n",
      "Iter 494080, Minibatch Loss= 0.145601, Training Accuracy= 0.94531\n",
      "Iter 495360, Minibatch Loss= 0.164577, Training Accuracy= 0.95312\n",
      "Iter 496640, Minibatch Loss= 0.098371, Training Accuracy= 0.98438\n",
      "Iter 497920, Minibatch Loss= 0.109722, Training Accuracy= 0.95312\n",
      "Iter 499200, Minibatch Loss= 0.086965, Training Accuracy= 0.97170\n",
      "Iter 500480, Minibatch Loss= 0.138703, Training Accuracy= 0.93750\n",
      "Iter 501760, Minibatch Loss= 0.127818, Training Accuracy= 0.95312\n",
      "Iter 503040, Minibatch Loss= 0.189143, Training Accuracy= 0.89062\n",
      "Iter 504320, Minibatch Loss= 0.163226, Training Accuracy= 0.93750\n",
      "Iter 505600, Minibatch Loss= 0.177318, Training Accuracy= 0.91406\n",
      "Iter 506880, Minibatch Loss= 0.142714, Training Accuracy= 0.94531\n",
      "Iter 508160, Minibatch Loss= 0.214986, Training Accuracy= 0.91406\n",
      "Iter 509440, Minibatch Loss= 0.156021, Training Accuracy= 0.93750\n",
      "Iter 510720, Minibatch Loss= 0.118093, Training Accuracy= 0.96094\n",
      "Iter 512000, Minibatch Loss= 0.407198, Training Accuracy= 0.84375\n",
      "Iter 513280, Minibatch Loss= 0.117776, Training Accuracy= 0.97656\n",
      "Iter 514560, Minibatch Loss= 0.143480, Training Accuracy= 0.94531\n",
      "Iter 515840, Minibatch Loss= 0.165796, Training Accuracy= 0.93750\n",
      "Iter 517120, Minibatch Loss= 0.143871, Training Accuracy= 0.93750\n",
      "Iter 518400, Minibatch Loss= 0.158871, Training Accuracy= 0.94531\n",
      "Iter 519680, Minibatch Loss= 0.171344, Training Accuracy= 0.92188\n",
      "Iter 520960, Minibatch Loss= 0.188665, Training Accuracy= 0.92188\n",
      "Iter 522240, Minibatch Loss= 0.280120, Training Accuracy= 0.89062\n",
      "Iter 523520, Minibatch Loss= 0.164028, Training Accuracy= 0.94531\n",
      "Iter 524800, Minibatch Loss= 0.126343, Training Accuracy= 0.95312\n",
      "Iter 526080, Minibatch Loss= 0.230644, Training Accuracy= 0.90625\n",
      "Iter 527360, Minibatch Loss= 0.097967, Training Accuracy= 0.96875\n",
      "Iter 528640, Minibatch Loss= 0.130867, Training Accuracy= 0.96875\n",
      "Iter 529920, Minibatch Loss= 0.166067, Training Accuracy= 0.92969\n",
      "Iter 531200, Minibatch Loss= 0.196371, Training Accuracy= 0.91406\n",
      "Iter 532480, Minibatch Loss= 0.174835, Training Accuracy= 0.92969\n",
      "Iter 533760, Minibatch Loss= 0.085918, Training Accuracy= 0.98438\n",
      "Iter 535040, Minibatch Loss= 0.101932, Training Accuracy= 0.98438\n",
      "Iter 536320, Minibatch Loss= 0.147015, Training Accuracy= 0.94531\n",
      "Iter 537600, Minibatch Loss= 0.137654, Training Accuracy= 0.96094\n",
      "Iter 538880, Minibatch Loss= 0.125803, Training Accuracy= 0.94531\n",
      "Iter 540160, Minibatch Loss= 0.098963, Training Accuracy= 0.98438\n",
      "Iter 541440, Minibatch Loss= 0.146321, Training Accuracy= 0.93750\n",
      "Iter 542720, Minibatch Loss= 0.195155, Training Accuracy= 0.90625\n",
      "Iter 544000, Minibatch Loss= 0.142084, Training Accuracy= 0.94531\n",
      "Iter 545280, Minibatch Loss= 0.158228, Training Accuracy= 0.95312\n",
      "Iter 546560, Minibatch Loss= 0.091686, Training Accuracy= 0.98438\n",
      "Iter 547840, Minibatch Loss= 0.101871, Training Accuracy= 0.95312\n",
      "Iter 549120, Minibatch Loss= 0.080788, Training Accuracy= 0.97170\n",
      "Iter 550400, Minibatch Loss= 0.130584, Training Accuracy= 0.93750\n",
      "Iter 551680, Minibatch Loss= 0.093553, Training Accuracy= 0.96094\n",
      "Iter 552960, Minibatch Loss= 0.187982, Training Accuracy= 0.92188\n",
      "Iter 554240, Minibatch Loss= 0.152074, Training Accuracy= 0.93750\n",
      "Iter 555520, Minibatch Loss= 0.180035, Training Accuracy= 0.92188\n",
      "Iter 556800, Minibatch Loss= 0.138087, Training Accuracy= 0.95312\n",
      "Iter 558080, Minibatch Loss= 0.208405, Training Accuracy= 0.91406\n",
      "Iter 559360, Minibatch Loss= 0.156349, Training Accuracy= 0.94531\n",
      "Iter 560640, Minibatch Loss= 0.114173, Training Accuracy= 0.95312\n",
      "Iter 561920, Minibatch Loss= 0.231688, Training Accuracy= 0.91406\n",
      "Iter 563200, Minibatch Loss= 0.113241, Training Accuracy= 0.96875\n",
      "Iter 564480, Minibatch Loss= 0.135016, Training Accuracy= 0.93750\n",
      "Iter 565760, Minibatch Loss= 0.165852, Training Accuracy= 0.94531\n",
      "Iter 567040, Minibatch Loss= 0.140787, Training Accuracy= 0.92969\n",
      "Iter 568320, Minibatch Loss= 0.148438, Training Accuracy= 0.95312\n",
      "Iter 569600, Minibatch Loss= 0.193212, Training Accuracy= 0.92969\n",
      "Iter 570880, Minibatch Loss= 0.182076, Training Accuracy= 0.92969\n",
      "Iter 572160, Minibatch Loss= 0.270539, Training Accuracy= 0.89062\n",
      "Iter 573440, Minibatch Loss= 0.158570, Training Accuracy= 0.94531\n",
      "Iter 574720, Minibatch Loss= 0.120582, Training Accuracy= 0.95312\n",
      "Iter 576000, Minibatch Loss= 0.224315, Training Accuracy= 0.90625\n",
      "Iter 577280, Minibatch Loss= 0.093726, Training Accuracy= 0.96875\n",
      "Iter 578560, Minibatch Loss= 0.123111, Training Accuracy= 0.96875\n",
      "Iter 579840, Minibatch Loss= 0.164151, Training Accuracy= 0.93750\n",
      "Iter 581120, Minibatch Loss= 0.191774, Training Accuracy= 0.90625\n",
      "Iter 582400, Minibatch Loss= 0.179278, Training Accuracy= 0.92969\n",
      "Iter 583680, Minibatch Loss= 0.085642, Training Accuracy= 0.97656\n",
      "Iter 584960, Minibatch Loss= 0.099169, Training Accuracy= 0.97656\n",
      "Iter 586240, Minibatch Loss= 0.145669, Training Accuracy= 0.94531\n",
      "Iter 587520, Minibatch Loss= 0.133284, Training Accuracy= 0.95312\n",
      "Iter 588800, Minibatch Loss= 0.119222, Training Accuracy= 0.95312\n",
      "Iter 590080, Minibatch Loss= 0.094193, Training Accuracy= 0.98438\n",
      "Iter 591360, Minibatch Loss= 0.132685, Training Accuracy= 0.94531\n",
      "Iter 592640, Minibatch Loss= 0.194578, Training Accuracy= 0.91406\n",
      "Iter 593920, Minibatch Loss= 0.136936, Training Accuracy= 0.95312\n",
      "Iter 595200, Minibatch Loss= 0.153470, Training Accuracy= 0.95312\n",
      "Iter 596480, Minibatch Loss= 0.089607, Training Accuracy= 0.98438\n",
      "Iter 597760, Minibatch Loss= 0.095972, Training Accuracy= 0.95312\n",
      "Iter 599040, Minibatch Loss= 0.077908, Training Accuracy= 0.97170\n",
      "Iter 600320, Minibatch Loss= 0.124300, Training Accuracy= 0.93750\n",
      "Iter 601600, Minibatch Loss= 0.089132, Training Accuracy= 0.96094\n",
      "Iter 602880, Minibatch Loss= 0.176893, Training Accuracy= 0.92969\n",
      "Iter 604160, Minibatch Loss= 0.153568, Training Accuracy= 0.93750\n",
      "Iter 605440, Minibatch Loss= 0.176675, Training Accuracy= 0.93750\n",
      "Iter 606720, Minibatch Loss= 0.133598, Training Accuracy= 0.95312\n",
      "Iter 608000, Minibatch Loss= 0.203062, Training Accuracy= 0.91406\n",
      "Iter 609280, Minibatch Loss= 0.146442, Training Accuracy= 0.95312\n",
      "Iter 610560, Minibatch Loss= 0.108645, Training Accuracy= 0.95312\n",
      "Iter 611840, Minibatch Loss= 0.166992, Training Accuracy= 0.94531\n",
      "Iter 613120, Minibatch Loss= 0.107595, Training Accuracy= 0.96875\n",
      "Iter 614400, Minibatch Loss= 0.130905, Training Accuracy= 0.94531\n",
      "Iter 615680, Minibatch Loss= 0.161595, Training Accuracy= 0.94531\n",
      "Iter 616960, Minibatch Loss= 0.134018, Training Accuracy= 0.92969\n",
      "Iter 618240, Minibatch Loss= 0.143215, Training Accuracy= 0.95312\n",
      "Iter 619520, Minibatch Loss= 0.190170, Training Accuracy= 0.92969\n",
      "Iter 620800, Minibatch Loss= 0.175411, Training Accuracy= 0.92969\n",
      "Iter 622080, Minibatch Loss= 0.359510, Training Accuracy= 0.86719\n",
      "Iter 623360, Minibatch Loss= 0.152801, Training Accuracy= 0.94531\n",
      "Iter 624640, Minibatch Loss= 0.112987, Training Accuracy= 0.96094\n",
      "Iter 625920, Minibatch Loss= 0.213207, Training Accuracy= 0.91406\n",
      "Iter 627200, Minibatch Loss= 0.088667, Training Accuracy= 0.97656\n",
      "Iter 628480, Minibatch Loss= 0.115810, Training Accuracy= 0.96875\n",
      "Iter 629760, Minibatch Loss= 0.156582, Training Accuracy= 0.93750\n",
      "Iter 631040, Minibatch Loss= 0.186763, Training Accuracy= 0.90625\n",
      "Iter 632320, Minibatch Loss= 0.172563, Training Accuracy= 0.93750\n",
      "Iter 633600, Minibatch Loss= 0.080509, Training Accuracy= 0.97656\n",
      "Iter 634880, Minibatch Loss= 0.094330, Training Accuracy= 0.97656\n",
      "Iter 636160, Minibatch Loss= 0.141889, Training Accuracy= 0.94531\n",
      "Iter 637440, Minibatch Loss= 0.128414, Training Accuracy= 0.95312\n",
      "Iter 638720, Minibatch Loss= 0.111919, Training Accuracy= 0.96094\n",
      "Iter 640000, Minibatch Loss= 0.091516, Training Accuracy= 0.98438\n",
      "Iter 641280, Minibatch Loss= 0.125550, Training Accuracy= 0.96094\n",
      "Iter 642560, Minibatch Loss= 0.189814, Training Accuracy= 0.91406\n",
      "Iter 643840, Minibatch Loss= 0.133492, Training Accuracy= 0.96094\n",
      "Iter 645120, Minibatch Loss= 0.148685, Training Accuracy= 0.96094\n",
      "Iter 646400, Minibatch Loss= 0.086561, Training Accuracy= 0.98438\n",
      "Iter 647680, Minibatch Loss= 0.090080, Training Accuracy= 0.95312\n",
      "Iter 648960, Minibatch Loss= 0.073704, Training Accuracy= 0.98113\n",
      "Iter 650240, Minibatch Loss= 0.117567, Training Accuracy= 0.93750\n",
      "Iter 651520, Minibatch Loss= 0.087998, Training Accuracy= 0.96875\n",
      "Iter 652800, Minibatch Loss= 0.169205, Training Accuracy= 0.92188\n",
      "Iter 654080, Minibatch Loss= 0.150360, Training Accuracy= 0.93750\n",
      "Iter 655360, Minibatch Loss= 0.171941, Training Accuracy= 0.92969\n",
      "Iter 656640, Minibatch Loss= 0.129460, Training Accuracy= 0.95312\n",
      "Iter 657920, Minibatch Loss= 0.195945, Training Accuracy= 0.92969\n",
      "Iter 659200, Minibatch Loss= 0.141460, Training Accuracy= 0.95312\n",
      "Iter 660480, Minibatch Loss= 0.103951, Training Accuracy= 0.95312\n",
      "Iter 661760, Minibatch Loss= 0.130820, Training Accuracy= 0.96875\n",
      "Iter 663040, Minibatch Loss= 0.103823, Training Accuracy= 0.96875\n",
      "Iter 664320, Minibatch Loss= 0.126977, Training Accuracy= 0.95312\n",
      "Iter 665600, Minibatch Loss= 0.158263, Training Accuracy= 0.94531\n",
      "Iter 666880, Minibatch Loss= 0.129941, Training Accuracy= 0.92969\n",
      "Iter 668160, Minibatch Loss= 0.137832, Training Accuracy= 0.94531\n",
      "Iter 669440, Minibatch Loss= 0.189409, Training Accuracy= 0.92969\n",
      "Iter 670720, Minibatch Loss= 0.168274, Training Accuracy= 0.92969\n",
      "Iter 672000, Minibatch Loss= 0.175296, Training Accuracy= 0.92188\n",
      "Iter 673280, Minibatch Loss= 0.154639, Training Accuracy= 0.94531\n",
      "Iter 674560, Minibatch Loss= 0.117193, Training Accuracy= 0.96094\n",
      "Iter 675840, Minibatch Loss= 0.210106, Training Accuracy= 0.89844\n",
      "Iter 677120, Minibatch Loss= 0.089220, Training Accuracy= 0.96875\n",
      "Iter 678400, Minibatch Loss= 0.110811, Training Accuracy= 0.97656\n",
      "Iter 679680, Minibatch Loss= 0.160543, Training Accuracy= 0.92188\n",
      "Iter 680960, Minibatch Loss= 0.184727, Training Accuracy= 0.91406\n",
      "Iter 682240, Minibatch Loss= 0.172094, Training Accuracy= 0.94531\n",
      "Iter 683520, Minibatch Loss= 0.078204, Training Accuracy= 0.98438\n",
      "Iter 684800, Minibatch Loss= 0.094082, Training Accuracy= 0.97656\n",
      "Iter 686080, Minibatch Loss= 0.142620, Training Accuracy= 0.94531\n",
      "Iter 687360, Minibatch Loss= 0.124403, Training Accuracy= 0.96094\n",
      "Iter 688640, Minibatch Loss= 0.109525, Training Accuracy= 0.96094\n",
      "Iter 689920, Minibatch Loss= 0.090257, Training Accuracy= 0.98438\n",
      "Iter 691200, Minibatch Loss= 0.127218, Training Accuracy= 0.94531\n",
      "Iter 692480, Minibatch Loss= 0.191009, Training Accuracy= 0.92188\n",
      "Iter 693760, Minibatch Loss= 0.130724, Training Accuracy= 0.96094\n",
      "Iter 695040, Minibatch Loss= 0.151398, Training Accuracy= 0.96094\n",
      "Iter 696320, Minibatch Loss= 0.095433, Training Accuracy= 0.96875\n",
      "Iter 697600, Minibatch Loss= 0.086918, Training Accuracy= 0.95312\n",
      "Iter 698880, Minibatch Loss= 0.071479, Training Accuracy= 0.98113\n",
      "Iter 700160, Minibatch Loss= 0.112218, Training Accuracy= 0.93750\n",
      "Iter 701440, Minibatch Loss= 0.100122, Training Accuracy= 0.95312\n",
      "Iter 702720, Minibatch Loss= 0.160032, Training Accuracy= 0.92969\n",
      "Iter 704000, Minibatch Loss= 0.147739, Training Accuracy= 0.93750\n",
      "Iter 705280, Minibatch Loss= 0.171303, Training Accuracy= 0.93750\n",
      "Iter 706560, Minibatch Loss= 0.126086, Training Accuracy= 0.95312\n",
      "Iter 707840, Minibatch Loss= 0.187325, Training Accuracy= 0.93750\n",
      "Iter 709120, Minibatch Loss= 0.134385, Training Accuracy= 0.95312\n",
      "Iter 710400, Minibatch Loss= 0.102604, Training Accuracy= 0.94531\n",
      "Iter 711680, Minibatch Loss= 0.101341, Training Accuracy= 0.97656\n",
      "Iter 712960, Minibatch Loss= 0.101997, Training Accuracy= 0.96875\n",
      "Iter 714240, Minibatch Loss= 0.126259, Training Accuracy= 0.95312\n",
      "Iter 715520, Minibatch Loss= 0.153768, Training Accuracy= 0.94531\n",
      "Iter 716800, Minibatch Loss= 0.134036, Training Accuracy= 0.92969\n",
      "Iter 718080, Minibatch Loss= 0.136940, Training Accuracy= 0.95312\n",
      "Iter 719360, Minibatch Loss= 0.187783, Training Accuracy= 0.92969\n",
      "Iter 720640, Minibatch Loss= 0.162947, Training Accuracy= 0.92969\n",
      "Iter 721920, Minibatch Loss= 0.319992, Training Accuracy= 0.86719\n",
      "Iter 723200, Minibatch Loss= 0.145072, Training Accuracy= 0.94531\n",
      "Iter 724480, Minibatch Loss= 0.101991, Training Accuracy= 0.96094\n",
      "Iter 725760, Minibatch Loss= 0.199515, Training Accuracy= 0.91406\n",
      "Iter 727040, Minibatch Loss= 0.079604, Training Accuracy= 0.97656\n",
      "Iter 728320, Minibatch Loss= 0.104260, Training Accuracy= 0.97656\n",
      "Iter 729600, Minibatch Loss= 0.148936, Training Accuracy= 0.93750\n",
      "Iter 730880, Minibatch Loss= 0.176612, Training Accuracy= 0.91406\n",
      "Iter 732160, Minibatch Loss= 0.172757, Training Accuracy= 0.94531\n",
      "Iter 733440, Minibatch Loss= 0.076516, Training Accuracy= 0.97656\n",
      "Iter 734720, Minibatch Loss= 0.088535, Training Accuracy= 0.97656\n",
      "Iter 736000, Minibatch Loss= 0.138691, Training Accuracy= 0.94531\n",
      "Iter 737280, Minibatch Loss= 0.117794, Training Accuracy= 0.96875\n",
      "Iter 738560, Minibatch Loss= 0.099026, Training Accuracy= 0.96875\n",
      "Iter 739840, Minibatch Loss= 0.084857, Training Accuracy= 0.98438\n",
      "Iter 741120, Minibatch Loss= 0.116547, Training Accuracy= 0.94531\n",
      "Iter 742400, Minibatch Loss= 0.190776, Training Accuracy= 0.92969\n",
      "Iter 743680, Minibatch Loss= 0.125785, Training Accuracy= 0.96875\n",
      "Iter 744960, Minibatch Loss= 0.143913, Training Accuracy= 0.96094\n",
      "Iter 746240, Minibatch Loss= 0.092032, Training Accuracy= 0.96875\n",
      "Iter 747520, Minibatch Loss= 0.081015, Training Accuracy= 0.95312\n",
      "Iter 748800, Minibatch Loss= 0.065792, Training Accuracy= 0.98113\n",
      "Iter 750080, Minibatch Loss= 0.105428, Training Accuracy= 0.94531\n",
      "Iter 751360, Minibatch Loss= 0.093269, Training Accuracy= 0.96094\n",
      "Iter 752640, Minibatch Loss= 0.151351, Training Accuracy= 0.93750\n",
      "Iter 753920, Minibatch Loss= 0.148800, Training Accuracy= 0.92969\n",
      "Iter 755200, Minibatch Loss= 0.163814, Training Accuracy= 0.93750\n",
      "Iter 756480, Minibatch Loss= 0.121743, Training Accuracy= 0.96094\n",
      "Iter 757760, Minibatch Loss= 0.181610, Training Accuracy= 0.94531\n",
      "Iter 759040, Minibatch Loss= 0.131883, Training Accuracy= 0.95312\n",
      "Iter 760320, Minibatch Loss= 0.095483, Training Accuracy= 0.96094\n",
      "Iter 761600, Minibatch Loss= 0.097697, Training Accuracy= 0.97656\n",
      "Iter 762880, Minibatch Loss= 0.096806, Training Accuracy= 0.97656\n",
      "Iter 764160, Minibatch Loss= 0.120038, Training Accuracy= 0.95312\n",
      "Iter 765440, Minibatch Loss= 0.150411, Training Accuracy= 0.94531\n",
      "Iter 766720, Minibatch Loss= 0.128899, Training Accuracy= 0.92969\n",
      "Iter 768000, Minibatch Loss= 0.127970, Training Accuracy= 0.94531\n",
      "Iter 769280, Minibatch Loss= 0.184411, Training Accuracy= 0.92969\n",
      "Iter 770560, Minibatch Loss= 0.155810, Training Accuracy= 0.92969\n",
      "Iter 771840, Minibatch Loss= 0.339845, Training Accuracy= 0.86719\n",
      "Iter 773120, Minibatch Loss= 0.139462, Training Accuracy= 0.95312\n",
      "Iter 774400, Minibatch Loss= 0.094768, Training Accuracy= 0.96094\n",
      "Iter 775680, Minibatch Loss= 0.187589, Training Accuracy= 0.91406\n",
      "Iter 776960, Minibatch Loss= 0.074641, Training Accuracy= 0.97656\n",
      "Iter 778240, Minibatch Loss= 0.099250, Training Accuracy= 0.97656\n",
      "Iter 779520, Minibatch Loss= 0.138918, Training Accuracy= 0.93750\n",
      "Iter 780800, Minibatch Loss= 0.171189, Training Accuracy= 0.92188\n",
      "Iter 782080, Minibatch Loss= 0.169466, Training Accuracy= 0.93750\n",
      "Iter 783360, Minibatch Loss= 0.072537, Training Accuracy= 0.97656\n",
      "Iter 784640, Minibatch Loss= 0.083525, Training Accuracy= 0.97656\n",
      "Iter 785920, Minibatch Loss= 0.135650, Training Accuracy= 0.93750\n",
      "Iter 787200, Minibatch Loss= 0.111190, Training Accuracy= 0.96094\n",
      "Iter 788480, Minibatch Loss= 0.091121, Training Accuracy= 0.95312\n",
      "Iter 789760, Minibatch Loss= 0.083501, Training Accuracy= 0.98438\n",
      "Iter 791040, Minibatch Loss= 0.108042, Training Accuracy= 0.96875\n",
      "Iter 792320, Minibatch Loss= 0.185437, Training Accuracy= 0.92969\n",
      "Iter 793600, Minibatch Loss= 0.126408, Training Accuracy= 0.96875\n",
      "Iter 794880, Minibatch Loss= 0.130206, Training Accuracy= 0.96094\n",
      "Iter 796160, Minibatch Loss= 0.106147, Training Accuracy= 0.95312\n",
      "Iter 797440, Minibatch Loss= 0.073268, Training Accuracy= 0.99219\n",
      "Iter 798720, Minibatch Loss= 0.060028, Training Accuracy= 0.98113\n",
      "Iter 800000, Minibatch Loss= 0.097680, Training Accuracy= 0.96094\n",
      "Iter 801280, Minibatch Loss= 0.081371, Training Accuracy= 0.96875\n",
      "Iter 802560, Minibatch Loss= 0.140154, Training Accuracy= 0.93750\n",
      "Iter 803840, Minibatch Loss= 0.141754, Training Accuracy= 0.93750\n",
      "Iter 805120, Minibatch Loss= 0.159665, Training Accuracy= 0.93750\n",
      "Iter 806400, Minibatch Loss= 0.121179, Training Accuracy= 0.95312\n",
      "Iter 807680, Minibatch Loss= 0.176160, Training Accuracy= 0.93750\n",
      "Iter 808960, Minibatch Loss= 0.130412, Training Accuracy= 0.95312\n",
      "Iter 810240, Minibatch Loss= 0.089774, Training Accuracy= 0.96094\n",
      "Iter 811520, Minibatch Loss= 0.104338, Training Accuracy= 0.96875\n",
      "Iter 812800, Minibatch Loss= 0.091438, Training Accuracy= 0.98438\n",
      "Iter 814080, Minibatch Loss= 0.116092, Training Accuracy= 0.95312\n",
      "Iter 815360, Minibatch Loss= 0.143911, Training Accuracy= 0.95312\n",
      "Iter 816640, Minibatch Loss= 0.116149, Training Accuracy= 0.92969\n",
      "Iter 817920, Minibatch Loss= 0.118598, Training Accuracy= 0.94531\n",
      "Iter 819200, Minibatch Loss= 0.162146, Training Accuracy= 0.93750\n",
      "Iter 820480, Minibatch Loss= 0.144790, Training Accuracy= 0.96094\n",
      "Iter 821760, Minibatch Loss= 0.341129, Training Accuracy= 0.87500\n",
      "Iter 823040, Minibatch Loss= 0.130041, Training Accuracy= 0.95312\n",
      "Iter 824320, Minibatch Loss= 0.079656, Training Accuracy= 0.96875\n",
      "Iter 825600, Minibatch Loss= 0.174016, Training Accuracy= 0.91406\n",
      "Iter 826880, Minibatch Loss= 0.068824, Training Accuracy= 0.98438\n",
      "Iter 828160, Minibatch Loss= 0.093217, Training Accuracy= 0.97656\n",
      "Iter 829440, Minibatch Loss= 0.121990, Training Accuracy= 0.93750\n",
      "Iter 830720, Minibatch Loss= 0.170552, Training Accuracy= 0.92188\n",
      "Iter 832000, Minibatch Loss= 0.159350, Training Accuracy= 0.94531\n",
      "Iter 833280, Minibatch Loss= 0.064162, Training Accuracy= 0.99219\n",
      "Iter 834560, Minibatch Loss= 0.077480, Training Accuracy= 0.97656\n",
      "Iter 835840, Minibatch Loss= 0.129865, Training Accuracy= 0.96094\n",
      "Iter 837120, Minibatch Loss= 0.105331, Training Accuracy= 0.96094\n",
      "Iter 838400, Minibatch Loss= 0.082729, Training Accuracy= 0.96094\n",
      "Iter 839680, Minibatch Loss= 0.073534, Training Accuracy= 0.98438\n",
      "Iter 840960, Minibatch Loss= 0.101523, Training Accuracy= 0.96094\n",
      "Iter 842240, Minibatch Loss= 0.171037, Training Accuracy= 0.92969\n",
      "Iter 843520, Minibatch Loss= 0.122568, Training Accuracy= 0.96875\n",
      "Iter 844800, Minibatch Loss= 0.122845, Training Accuracy= 0.96094\n",
      "Iter 846080, Minibatch Loss= 0.080020, Training Accuracy= 0.96875\n",
      "Iter 847360, Minibatch Loss= 0.068330, Training Accuracy= 0.99219\n",
      "Iter 848640, Minibatch Loss= 0.053234, Training Accuracy= 0.98113\n",
      "Iter 849920, Minibatch Loss= 0.091143, Training Accuracy= 0.96875\n",
      "Iter 851200, Minibatch Loss= 0.078958, Training Accuracy= 0.97656\n",
      "Iter 852480, Minibatch Loss= 0.140726, Training Accuracy= 0.93750\n",
      "Iter 853760, Minibatch Loss= 0.131022, Training Accuracy= 0.94531\n",
      "Iter 855040, Minibatch Loss= 0.149753, Training Accuracy= 0.93750\n",
      "Iter 856320, Minibatch Loss= 0.119093, Training Accuracy= 0.95312\n",
      "Iter 857600, Minibatch Loss= 0.170618, Training Accuracy= 0.92969\n",
      "Iter 858880, Minibatch Loss= 0.128013, Training Accuracy= 0.96094\n",
      "Iter 860160, Minibatch Loss= 0.082205, Training Accuracy= 0.96094\n",
      "Iter 861440, Minibatch Loss= 0.171952, Training Accuracy= 0.93750\n",
      "Iter 862720, Minibatch Loss= 0.087989, Training Accuracy= 0.98438\n",
      "Iter 864000, Minibatch Loss= 0.111280, Training Accuracy= 0.96094\n",
      "Iter 865280, Minibatch Loss= 0.137083, Training Accuracy= 0.95312\n",
      "Iter 866560, Minibatch Loss= 0.107062, Training Accuracy= 0.93750\n",
      "Iter 867840, Minibatch Loss= 0.111327, Training Accuracy= 0.93750\n",
      "Iter 869120, Minibatch Loss= 0.137012, Training Accuracy= 0.95312\n",
      "Iter 870400, Minibatch Loss= 0.137283, Training Accuracy= 0.96094\n",
      "Iter 871680, Minibatch Loss= 0.308315, Training Accuracy= 0.88281\n",
      "Iter 872960, Minibatch Loss= 0.122728, Training Accuracy= 0.95312\n",
      "Iter 874240, Minibatch Loss= 0.073407, Training Accuracy= 0.96094\n",
      "Iter 875520, Minibatch Loss= 0.164622, Training Accuracy= 0.92188\n",
      "Iter 876800, Minibatch Loss= 0.065025, Training Accuracy= 0.98438\n",
      "Iter 878080, Minibatch Loss= 0.088460, Training Accuracy= 0.97656\n",
      "Iter 879360, Minibatch Loss= 0.109994, Training Accuracy= 0.95312\n",
      "Iter 880640, Minibatch Loss= 0.165894, Training Accuracy= 0.92969\n",
      "Iter 881920, Minibatch Loss= 0.146332, Training Accuracy= 0.94531\n",
      "Iter 883200, Minibatch Loss= 0.061209, Training Accuracy= 0.99219\n",
      "Iter 884480, Minibatch Loss= 0.074907, Training Accuracy= 0.97656\n",
      "Iter 885760, Minibatch Loss= 0.128288, Training Accuracy= 0.96094\n",
      "Iter 887040, Minibatch Loss= 0.098690, Training Accuracy= 0.96875\n",
      "Iter 888320, Minibatch Loss= 0.074833, Training Accuracy= 0.96875\n",
      "Iter 889600, Minibatch Loss= 0.065895, Training Accuracy= 0.98438\n",
      "Iter 890880, Minibatch Loss= 0.098814, Training Accuracy= 0.96094\n",
      "Iter 892160, Minibatch Loss= 0.158473, Training Accuracy= 0.92969\n",
      "Iter 893440, Minibatch Loss= 0.120207, Training Accuracy= 0.96875\n",
      "Iter 894720, Minibatch Loss= 0.117240, Training Accuracy= 0.96094\n",
      "Iter 896000, Minibatch Loss= 0.073527, Training Accuracy= 0.97656\n",
      "Iter 897280, Minibatch Loss= 0.064544, Training Accuracy= 0.99219\n",
      "Iter 898560, Minibatch Loss= 0.047212, Training Accuracy= 0.98113\n",
      "Iter 899840, Minibatch Loss= 0.085121, Training Accuracy= 0.96875\n",
      "Iter 901120, Minibatch Loss= 0.093164, Training Accuracy= 0.96094\n",
      "Iter 902400, Minibatch Loss= 0.135966, Training Accuracy= 0.94531\n",
      "Iter 903680, Minibatch Loss= 0.127013, Training Accuracy= 0.93750\n",
      "Iter 904960, Minibatch Loss= 0.143232, Training Accuracy= 0.93750\n",
      "Iter 906240, Minibatch Loss= 0.116448, Training Accuracy= 0.95312\n",
      "Iter 907520, Minibatch Loss= 0.163193, Training Accuracy= 0.92188\n",
      "Iter 908800, Minibatch Loss= 0.124492, Training Accuracy= 0.96094\n",
      "Iter 910080, Minibatch Loss= 0.074982, Training Accuracy= 0.96094\n",
      "Iter 911360, Minibatch Loss= 0.177519, Training Accuracy= 0.92969\n",
      "Iter 912640, Minibatch Loss= 0.084487, Training Accuracy= 0.98438\n",
      "Iter 913920, Minibatch Loss= 0.105558, Training Accuracy= 0.96094\n",
      "Iter 915200, Minibatch Loss= 0.131878, Training Accuracy= 0.95312\n",
      "Iter 916480, Minibatch Loss= 0.101904, Training Accuracy= 0.93750\n",
      "Iter 917760, Minibatch Loss= 0.103516, Training Accuracy= 0.93750\n",
      "Iter 919040, Minibatch Loss= 0.123642, Training Accuracy= 0.96094\n",
      "Iter 920320, Minibatch Loss= 0.131667, Training Accuracy= 0.96094\n",
      "Iter 921600, Minibatch Loss= 0.263924, Training Accuracy= 0.90625\n",
      "Iter 922880, Minibatch Loss= 0.117059, Training Accuracy= 0.95312\n",
      "Iter 924160, Minibatch Loss= 0.065435, Training Accuracy= 0.96875\n",
      "Iter 925440, Minibatch Loss= 0.153831, Training Accuracy= 0.92188\n",
      "Iter 926720, Minibatch Loss= 0.060083, Training Accuracy= 0.98438\n",
      "Iter 928000, Minibatch Loss= 0.085328, Training Accuracy= 0.96875\n",
      "Iter 929280, Minibatch Loss= 0.101023, Training Accuracy= 0.96094\n",
      "Iter 930560, Minibatch Loss= 0.160726, Training Accuracy= 0.92969\n",
      "Iter 931840, Minibatch Loss= 0.136591, Training Accuracy= 0.95312\n",
      "Iter 933120, Minibatch Loss= 0.057670, Training Accuracy= 0.99219\n",
      "Iter 934400, Minibatch Loss= 0.071062, Training Accuracy= 0.98438\n",
      "Iter 935680, Minibatch Loss= 0.126054, Training Accuracy= 0.96094\n",
      "Iter 936960, Minibatch Loss= 0.092295, Training Accuracy= 0.96875\n",
      "Iter 938240, Minibatch Loss= 0.067975, Training Accuracy= 0.96875\n",
      "Iter 939520, Minibatch Loss= 0.060500, Training Accuracy= 0.98438\n",
      "Iter 940800, Minibatch Loss= 0.096976, Training Accuracy= 0.96094\n",
      "Iter 942080, Minibatch Loss= 0.147862, Training Accuracy= 0.93750\n",
      "Iter 943360, Minibatch Loss= 0.116004, Training Accuracy= 0.96875\n",
      "Iter 944640, Minibatch Loss= 0.111164, Training Accuracy= 0.96094\n",
      "Iter 945920, Minibatch Loss= 0.075685, Training Accuracy= 0.97656\n",
      "Iter 947200, Minibatch Loss= 0.060654, Training Accuracy= 0.99219\n",
      "Iter 948480, Minibatch Loss= 0.041373, Training Accuracy= 0.99057\n",
      "Iter 949760, Minibatch Loss= 0.078778, Training Accuracy= 0.96875\n",
      "Iter 951040, Minibatch Loss= 0.107113, Training Accuracy= 0.96094\n",
      "Iter 952320, Minibatch Loss= 0.129087, Training Accuracy= 0.95312\n",
      "Iter 953600, Minibatch Loss= 0.127718, Training Accuracy= 0.92969\n",
      "Iter 954880, Minibatch Loss= 0.137065, Training Accuracy= 0.93750\n",
      "Iter 956160, Minibatch Loss= 0.113521, Training Accuracy= 0.96094\n",
      "Iter 957440, Minibatch Loss= 0.155304, Training Accuracy= 0.92188\n",
      "Iter 958720, Minibatch Loss= 0.120350, Training Accuracy= 0.96094\n",
      "Iter 960000, Minibatch Loss= 0.066645, Training Accuracy= 0.96875\n",
      "Iter 961280, Minibatch Loss= 0.157871, Training Accuracy= 0.94531\n",
      "Iter 962560, Minibatch Loss= 0.081552, Training Accuracy= 0.97656\n",
      "Iter 963840, Minibatch Loss= 0.099761, Training Accuracy= 0.96875\n",
      "Iter 965120, Minibatch Loss= 0.127386, Training Accuracy= 0.96094\n",
      "Iter 966400, Minibatch Loss= 0.097229, Training Accuracy= 0.93750\n",
      "Iter 967680, Minibatch Loss= 0.096722, Training Accuracy= 0.94531\n",
      "Iter 968960, Minibatch Loss= 0.114433, Training Accuracy= 0.97656\n",
      "Iter 970240, Minibatch Loss= 0.128745, Training Accuracy= 0.96094\n",
      "Iter 971520, Minibatch Loss= 0.220817, Training Accuracy= 0.89844\n",
      "Iter 972800, Minibatch Loss= 0.112420, Training Accuracy= 0.95312\n",
      "Iter 974080, Minibatch Loss= 0.058546, Training Accuracy= 0.97656\n",
      "Iter 975360, Minibatch Loss= 0.141014, Training Accuracy= 0.93750\n",
      "Iter 976640, Minibatch Loss= 0.055861, Training Accuracy= 0.98438\n",
      "Iter 977920, Minibatch Loss= 0.086322, Training Accuracy= 0.97656\n",
      "Iter 979200, Minibatch Loss= 0.093389, Training Accuracy= 0.96875\n",
      "Iter 980480, Minibatch Loss= 0.155655, Training Accuracy= 0.94531\n",
      "Iter 981760, Minibatch Loss= 0.124977, Training Accuracy= 0.96094\n",
      "Iter 983040, Minibatch Loss= 0.055050, Training Accuracy= 0.99219\n",
      "Iter 984320, Minibatch Loss= 0.067960, Training Accuracy= 0.98438\n",
      "Iter 985600, Minibatch Loss= 0.125544, Training Accuracy= 0.96875\n",
      "Iter 986880, Minibatch Loss= 0.085583, Training Accuracy= 0.98438\n",
      "Iter 988160, Minibatch Loss= 0.060507, Training Accuracy= 0.97656\n",
      "Iter 989440, Minibatch Loss= 0.056146, Training Accuracy= 0.98438\n",
      "Iter 990720, Minibatch Loss= 0.095179, Training Accuracy= 0.96094\n",
      "Iter 992000, Minibatch Loss= 0.135830, Training Accuracy= 0.93750\n",
      "Iter 993280, Minibatch Loss= 0.112211, Training Accuracy= 0.96875\n",
      "Iter 994560, Minibatch Loss= 0.106946, Training Accuracy= 0.96094\n",
      "Iter 995840, Minibatch Loss= 0.082005, Training Accuracy= 0.96875\n",
      "Iter 997120, Minibatch Loss= 0.057353, Training Accuracy= 0.99219\n",
      "Iter 998400, Minibatch Loss= 0.035904, Training Accuracy= 0.99057\n",
      "Iter 999680, Minibatch Loss= 0.072796, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.957028\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       seqlen: batch_seqlen})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y,\n",
    "                                             seqlen: batch_seqlen})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = testset.data\n",
    "    test_label = testset.labels\n",
    "    test_seqlen = testset.seqlen\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                      seqlen: test_seqlen}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
