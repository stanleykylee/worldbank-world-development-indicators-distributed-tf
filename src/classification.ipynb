{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import collections\n",
    "\n",
    "def load_dataset(dataset, target_dtype, features_dtype, target_column=-1):\n",
    "    Dataset = collections.namedtuple('Dataset', ['data', 'target'])\n",
    "    data, target = [], []\n",
    "    for row in dataset:\n",
    "        target.append(row.pop(target_column))\n",
    "        data.append(np.asarray(row, dtype=features_dtype))\n",
    "    \n",
    "    target = np.array(target, dtype=target_dtype)\n",
    "    data = np.array(data)\n",
    "    return Dataset(data=data, target=target)\n",
    "\n",
    "# Data sets\n",
    "#IRIS_TRAINING = \"time-series.csv\"\n",
    "#IRIS_TEST = \"time-series.csv\"\n",
    "\n",
    "file=open(\"time-series.csv\",\"r\")\n",
    "data=list()\n",
    "for line in file:\n",
    "    data.append(line.split(','))\n",
    "file.close()\n",
    "random.shuffle(data)\n",
    "train_data = data[:int((len(data)+1)*.80)] #Remaining 80% to training set\n",
    "test_data = data[int(len(data)*.80+1):] #Splits 20% data to test set\n",
    "\n",
    "# Load datasets.\n",
    "training_set = load_dataset(\n",
    "  dataset=train_data,\n",
    "  target_dtype=np.float32,\n",
    "  features_dtype=np.float32)\n",
    "test_set = load_dataset(\n",
    "  dataset=test_data,\n",
    "  target_dtype=np.float32,\n",
    "  features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001CB16D03C18>, '_task_type': None, '_environment': 'local', '_task_id': 0, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_keep_checkpoint_max': 5, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=24)]\n",
    "\n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                          hidden_units=[30, 50, 20, 10],\n",
    "                                          n_classes=2,\n",
    "                                          model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "def get_train_inputs():\n",
    "    training_set.target[training_set.target < 5] = 0\n",
    "    training_set.target[training_set.target > 5] = 1\n",
    "    x = tf.constant(training_set.data)\n",
    "    y = tf.constant(training_set.target)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 5.05058e+06\n",
      "INFO:tensorflow:global_step/sec: 71.264\n",
      "INFO:tensorflow:step = 101, loss = 8578.08\n",
      "INFO:tensorflow:global_step/sec: 71.9063\n",
      "INFO:tensorflow:step = 201, loss = 2624.98\n",
      "INFO:tensorflow:global_step/sec: 68.4047\n",
      "INFO:tensorflow:step = 301, loss = 2299.11\n",
      "INFO:tensorflow:global_step/sec: 65.5281\n",
      "INFO:tensorflow:step = 401, loss = 6921.98\n",
      "INFO:tensorflow:global_step/sec: 67.7311\n",
      "INFO:tensorflow:step = 501, loss = 1580.12\n",
      "INFO:tensorflow:global_step/sec: 67.0255\n",
      "INFO:tensorflow:step = 601, loss = 915.381\n",
      "INFO:tensorflow:global_step/sec: 65.4853\n",
      "INFO:tensorflow:step = 701, loss = 919.356\n",
      "INFO:tensorflow:global_step/sec: 66.7562\n",
      "INFO:tensorflow:step = 801, loss = 625.0\n",
      "INFO:tensorflow:global_step/sec: 65.593\n",
      "INFO:tensorflow:step = 901, loss = 484.446\n",
      "INFO:tensorflow:global_step/sec: 63.1428\n",
      "INFO:tensorflow:step = 1001, loss = 426.216\n",
      "INFO:tensorflow:global_step/sec: 64.8043\n",
      "INFO:tensorflow:step = 1101, loss = 393.067\n",
      "INFO:tensorflow:global_step/sec: 65.8744\n",
      "INFO:tensorflow:step = 1201, loss = 289.44\n",
      "INFO:tensorflow:global_step/sec: 66.2026\n",
      "INFO:tensorflow:step = 1301, loss = 500.604\n",
      "INFO:tensorflow:global_step/sec: 61.2803\n",
      "INFO:tensorflow:step = 1401, loss = 174.051\n",
      "INFO:tensorflow:global_step/sec: 66.1367\n",
      "INFO:tensorflow:step = 1501, loss = 159.777\n",
      "INFO:tensorflow:global_step/sec: 64.6784\n",
      "INFO:tensorflow:step = 1601, loss = 163.408\n",
      "INFO:tensorflow:global_step/sec: 66.7339\n",
      "INFO:tensorflow:step = 1701, loss = 287.162\n",
      "INFO:tensorflow:global_step/sec: 62.8444\n",
      "INFO:tensorflow:step = 1801, loss = 110.846\n",
      "INFO:tensorflow:global_step/sec: 65.1855\n",
      "INFO:tensorflow:step = 1901, loss = 94.6653\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/iris_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 53.5907.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'feature_columns': (_RealValuedColumn(column_name='', dimension=24, default_value=None, dtype=tf.float32, normalizer=None),), 'gradient_clip_norm': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x000001CB16775CC0>, 'optimizer': None, 'dropout': None, 'hidden_units': [30, 50, 20, 10], 'activation_fn': <function relu at 0x000001CB1894ED90>, 'input_layer_min_slice_size': None, 'embedding_lr_multipliers': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "classifier.fit(input_fn=get_train_inputs, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tf-cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-05-04-07:21:52\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-05-04-07:21:52\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.70241, accuracy/baseline_label_mean = 0.422088, accuracy/threshold_0.500000_mean = 0.70241, auc = 0.756859, global_step = 2000, labels/actual_label_mean = 0.422088, labels/prediction_mean = 0.571336, loss = 77.0289, precision/positive_threshold_0.500000_mean = 0.610714, recall/positive_threshold_0.500000_mean = 0.813511\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "\n",
      "Test Accuracy: 0.702410\n",
      "\n",
      "New Samples, Class Predictions:    [0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the test inputs\n",
    "def get_test_inputs():\n",
    "    test_set.target[test_set.target < 5] = 0\n",
    "    test_set.target[test_set.target > 5] = 1\n",
    "    x = tf.constant(test_set.data)\n",
    "    y = tf.constant(test_set.target)\n",
    "    return x, y\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=get_test_inputs, steps=1)[\"accuracy\"]\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "# Classify two new flower samples.\n",
    "def new_samples():\n",
    "    return np.array(\n",
    "  [[5.28923887058821E+01,3.04600220000000E+07,1.63233867085543E+00,4.84632109888550E+01,5.17815581804496E+00,1.92868014777594E+01,6.79631210347290E+01,6.74697763553599E+00,1.34159118941963E+02,3.20368789652710E+01,6.97565625034177E+00,6.94642591592048E+00,9.50779920000000E+07,4.02370560829584E+01,2.74199628024623E+00,4.64485044838654E+01,4.54869433081422E+01,4.74570928049574E+01,4.74301269937098E+01,4.96088497279859E+01,8.23161421257336E+01,8.92217139172395E+01,4.35389734769129E+01,6.46179700000000E+07],\n",
    "   [5.20657577073686E+01,3.54777630000000E+07,1.57343623734931E+00,5.02344036142858E+01,5.26417871495310E+00,1.78885490585671E+01,6.56435137434607E+01,6.96815521546032E+00,1.34105211273476E+02,3.43564862565393E+01,7.57422160886158E+00,6.97889297590332E+00,1.03263656000000E+08,4.24020583563869E+01,2.81190562726906E+00,4.81650989725272E+01,4.78622276218487E+01,4.66117901366285E+01,4.91743524731534E+01,4.96060327349811E+01,8.50966572029520E+01,9.24149155513926E+01,4.43062195793519E+01,6.77858930000000E+07]], dtype=np.float32)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=new_samples))\n",
    "\n",
    "print(\n",
    "  \"New Samples, Class Predictions:    {}\\n\"\n",
    "  .format(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
